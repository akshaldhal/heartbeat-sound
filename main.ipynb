{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torchaudio\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the CSV file\n",
    "df = pd.read_csv('extracted/set_a.csv')\n",
    "\n",
    "# Clean the dataset\n",
    "df_cleaned = df[~df['fname'].str.contains('unlabelled|^__') & df['label'].notnull()]\n",
    "df_cleaned.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Define a function to extract mel-spectrograms using Torchaudio\n",
    "def extract_mel_spectrogram(file_path, duration=5, sr=22050, n_mels=128):\n",
    "    try:\n",
    "        # Load the audio file\n",
    "        waveform, sample_rate = torchaudio.load(file_path)\n",
    "        \n",
    "        # Resample if necessary\n",
    "        if sample_rate != sr:\n",
    "            resampler = torchaudio.transforms.Resample(orig_freq=sample_rate, new_freq=sr)\n",
    "            waveform = resampler(waveform)\n",
    "\n",
    "        # Trim or pad the waveform to ensure consistent duration\n",
    "        num_samples = sr * duration\n",
    "        if waveform.size(1) > num_samples:\n",
    "            waveform = waveform[:, :num_samples]\n",
    "        else:\n",
    "            waveform = torch.nn.functional.pad(waveform, (0, num_samples - waveform.size(1)))\n",
    "\n",
    "        # Compute the mel-spectrogram\n",
    "        mel_spectrogram = torchaudio.transforms.MelSpectrogram(sample_rate=sr, n_mels=n_mels)(waveform)\n",
    "        \n",
    "        # Convert to decibels\n",
    "        mel_spectrogram_db = torchaudio.transforms.AmplitudeToDB()(mel_spectrogram)\n",
    "\n",
    "        return mel_spectrogram_db.squeeze().numpy()  # Squeeze to remove unnecessary dimensions\n",
    "    except Exception as e:\n",
    "        print(f\"Error encountered while parsing file: {file_path}, {str(e)}\")\n",
    "        return np.zeros((n_mels, 44))  # Fixed shape of the spectrogram (128 mel bands, 44 frames)\n",
    "\n",
    "# Apply the extraction function to each audio file\n",
    "df_cleaned['mel_spectrogram'] = df_cleaned['fname'].apply(lambda x: extract_mel_spectrogram(x))\n",
    "\n",
    "# Encode the labels\n",
    "le = LabelEncoder()\n",
    "df_cleaned['label_encoded'] = le.fit_transform(df_cleaned['label'])\n",
    "\n",
    "# Convert mel-spectrograms to numpy array\n",
    "X = np.array([s.flatten() for s in df_cleaned['mel_spectrogram'].tolist()])\n",
    "\n",
    "# Reshape X to fit the model (batch size, channels, height, width)\n",
    "X = X.reshape(X.shape[0], 128, -1, 1)  # Assuming the second dimension is flexible\n",
    "\n",
    "# Create a custom dataset for PyTorch\n",
    "class AudioDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.tensor(X, dtype=torch.float32)\n",
    "        self.y = torch.tensor(y, dtype=torch.long)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "# Split into train and test datasets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, df_cleaned['label_encoded'].values, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create PyTorch datasets and data loaders\n",
    "train_dataset = AudioDataset(X_train, y_train)\n",
    "test_dataset = AudioDataset(X_test, y_test)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Define a CNN model\n",
    "class CNNModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNModel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=(3, 3), padding='same')  # 1 input channel (grayscale)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=(3, 3), padding='same')\n",
    "        self.pool = nn.MaxPool2d(kernel_size=(2, 2))\n",
    "        self.fc1 = nn.Linear(64 * 32 * 22, 128)  # Adjust size based on the output dimensions after pooling\n",
    "        self.fc2 = nn.Linear(128, len(np.unique(y_train)))  # Output layer for number of classes\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(torch.relu(self.conv1(x)))\n",
    "        x = self.pool(torch.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 64 * 32 * 22)  # Flatten the tensor\n",
    "        x = self.dropout(torch.relu(self.fc1(x)))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Initialize the model, loss function, and optimizer\n",
    "model = CNNModel()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training the model\n",
    "num_epochs = 50\n",
    "train_loss_history = []\n",
    "train_acc_history = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for inputs, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Calculate accuracy\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    epoch_acc = 100 * correct / total\n",
    "    train_loss_history.append(epoch_loss)\n",
    "    train_acc_history.append(epoch_acc)\n",
    "    \n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}, Accuracy: {epoch_acc:.2f}%')\n",
    "\n",
    "# Testing the model\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "test_accuracy = 100 * correct / total\n",
    "print(f'Test Accuracy: {test_accuracy:.2f}%')\n",
    "\n",
    "# Plot training loss and accuracy curves\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_loss_history, label='Training Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss Over Time')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(train_acc_history, label='Training Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.title('Training Accuracy Over Time')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
